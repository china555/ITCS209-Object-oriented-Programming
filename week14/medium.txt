Automated Discovery of Product Feature 
Inferences within Large Scale Implicit Social Media 
Data 

Suppawong Tuarob  Sunghoon Lim  
Faculty of Information and  Industrial and Manufacturing Engineering  
Communication Technology  The Pennsylvania State University  
Mahidol University, Thailand  University Park, PA 16802  

Email: suppawong.tua@mahidol.edu Email: slim@psu.edu 
Conrad S. Tucker 
Engineering Design and Industrial and Manufacturing Engineering 
The Pennsylvania State University 
University Park, PA 16802 
Email: ctucker4@psu.edu 

Recently, social media has emerged as an alternative, viable source to extract large-scale, heterogeneous product features in a time and cost ef.cient manner. One of the challenges of utilizing social media data to inform product design decisions is the existence of implicit data such as sarcasm, which ac.counts for 22.75% of social media data, and can potentially create bias in the predictive models that learn from such data sources. For example, if a customer says “I just love wait.ing all day while this song downloads”, an automated product feature extraction model may incorrectly associate a positive sentiment of “love” to the cell phone’s ability to download. While traditional text mining techniques are designed to han.dle well-formed text where product features are explicitly in.ferred from the combination of words, these tools would fail to process these social messages that include implicit product feature information. In this paper, we propose a method that enables designers to utilize implicit social media data by trans.lating each implicit message into its equivalent explicit form, using the word concurrence network. A case study of Twitter messages that discuss smartphone features is used to validate the proposed method. The results from the experiment not only show that the proposed method improves the interpretability of implicit messages, but also sheds light on potential appli.cations in the design domains where this work could be ex.tended. 

1 Introduction 
The rigorous competition in the market space drives de.signers to create products that better satisfy the majority of customers in a resource ef.cient manner. Oftentimes, it is cru.cial that designers are familiar with target customers’ needs and preferences, in order to incorporate preferable features and remove weak elements from a design artifact. Recently, liter.ature has shown that information generated by social media users could prove critical to product designers in learning rele.vant preferences towards products/product features [1–6]. 

Technological advancements in digital communication has allowed many social media platforms to emerge as an al.ternative means for communication and information exchange in a timely and seamless manner. Literature in various .elds of study has shown successful applications that rely on informa.tion extracted from large scale social media data, such as min.ing healthcare-related information for disease prediction [7–9], detecting earthquake warnings and emergence needs due to natural disasters [10, 11], predicting .nancial market move.ment [12, 13], etc. 
In the design informatics domain, despite the traditional methods that extract customers’ preferences from online prod.uct reviews, recent .ndings have illustrated that social net.works could also serve as a viable source of information for mining customers’ opinions towards products/product fea.tures, due to its fast publication, wide range of users, accessi.bility, and heterogeneity of contents that provides an opportu.nity for customers to express opinions about products outside the review sites [2]. A data driven methodology has been pro.posed to automatically discover notable product features men.tioned in social networks [5]. Later, such notable product fea.ture information is incorporated into a decision support frame.work that helps designers to develop next-generation prod.ucts [2]. Furthermore, large scale social media data has been established as a viable platform to automatically discover in.novative users in social networks [1, 4]. Such innovative users could prove critical to product design and development as they help designers to discover relevant product feature preferences months or even years before they are desired by general cus.tomers. 
Implicit speech is a form of language usage in which the actual meaning is intended to be comprehended, but not di.rectly stated. A majority manifestation of implicit speech in.cludes sarcasm, which has become not only abundant, but also a norm in social networks. Maynard and Greenwood found that roughly 22.75% of social media data is sarcastic [14]. While it is evident that knowledge extracted from social media data is useful to product designers, the applicability of such data pertains to the portion expressed in explicit forms, due to the limitation of the underlying natural language processing algo.rithms that assume the explicit, well-formed textual input. As a result, implicit information would be either treated as noises or misinterpreted, resulting in inaccurate recommendation of product design decision support systems that process the infor.mation from large scale social media data. Hence, the ability to automatically understand and correctly interpret such implicit information in social networks would not only reduce the er.rors caused by methods that are not speci.cally designed to handle implicit information, but also allow the methodologies to make use of additional implicit data that would have tradi.tionally been disregarded due to being treated as noise. 
Examples of explicit and implicit social media messages are given below: 
Explicit “My old 7 inch Samsung Galaxy Tab 
is my #1 travel companion -perfect 

size & functionality.” Implicit “I love when my blackberry 
bold screen freezes, the iphone 

4 is definitely on my list of 

#13thingsiwant right now” 
The .rst example is considered explicit because it can be directly inferred from both keywords and the grammatical structure that the user may be satis.ed with the perfect size and functionality of his/her Samsung Galaxy Tab. On the con.trary, the second example does not give any direct information about the screen feature of his/her Blackberry Bold, and hence is implicit, though it may be inferred that this particular user may feel dissatis.ed with his/her Blackberry Bold due to its frozen screen. If these implicit social media messages remain untreated, two problems could occur: 
1. 	
Many data mining algorithms are extraction-based that would classify a social media message whether it is useful or not. Such methods would disregard such implicit data where explicit knowledge could not be extracted, resulting in low utilization of useful data. 

2. 	
Sarcastic social media messages may either exag.gerate (i.e. “Apparently the new iphone 5 helps you lose weight, you buy it and you can’t afford food for a month.”) 


or oppose (i.e. “HOLY SH**!... The iPhone 5 can now have 5 rows of icons. Too amazing. #sarcasm”) the original meaning. The traditional text mining techniques are incapable of cor.rectly interpreting the true meaning of these untreated social media messages. 

Regardless of all the useful applications that emerge from social media data, being able to automatically explicate the implicit social media data would not only increase the perfor.mance of the existing natural language processing techniques, but would also enable discovery of real important product fea.tures that exist in the implicit data. 
Processing social media data has been one of the biggest challenges for researchers. Traditional natural language pro.cessing techniques that have been shown to work well on tra.ditional documents are reported to fail or under-perform when applied on social media data, whose natures differ from tradi.tional documents in the following ways: 
1. 	
Social media data is high-dimensional, but sparse. A unit of social media document (aka message) is short, con.taining only one or two sentences. Some social media ser.vices, such as Twitter, enforce the length of a message, urging the users to be creative and use their own combina.tion of word forms to express their opinions within limited context. Traditional techniques for interpreting seman.tics from documents would fail on social media data due to insuf.ciency in textual content [7]. Furthermore, the high-dimensionality caused by using creative word forms would prevent such traditional techniques from .nding se.mantic similarity among the pool of social media mes.sages. 

2. 	
Social media data is noisy. Noise in social media data comes in multiple forms such as grammatical errors (e.g., ‘‘In the middle of the day and takes off running’’), intentional/unintentional typographical errors (e.g., ‘‘iphone 4s sooo COOOOLLLL!’’), and symbolic word forms (e.g., ‘‘:-/’’, ‘‘LOL’’). Since traditional text processing techniques assume documents to be well-formed and grammatically corrected [15], they would fail to operate on social media data. 



Existing attempts to interpret the semantic meaning be.hind implicit social media and relevant kinds of data (i.e. prod.uct reviews) include machine learning based implicit sentence detection algorithms proposed by Tsur et al. [16, 17]. How.ever, their methods only identify whether a piece of textual information is sarcastic or not. The work presented in this pa.per extends the previous literature by further extracting true meaning from social media messages whose context related to products/product features are implicit. 
This paper presents a mathematical model based on the heterogeneous co-word network patterns in order to translate implicit context towards a particular product or product feature into the explicit equivalence. A co-word network (or word co.occurrence network) is a graph where each node represents a unique word, and an undirected edge represents the frequency of co-occurrence of the two words. In this work, the network is augmented to incorporate parts of speech into each word. The intuition behind using the co-word network is that even though a message may be implicit, the similar combination of the words may have been used by other users who express their messages more explicitly. For example, given an implicit message “wow I have to squint to read this on the screen”, other users may have used the terms squint and screen in a more explicit context such as “Don’t make me squint @user -your mobile banner needs work on my tiny screen iPhone 5S.” If the combination of the words squint and screen occurs in the messages that contain the word tiny frequently enough, then the system would be able to relate the original message to a more explicit set of terms. Particularly, the system would be able to interpret that the user thinks that the screen feature of this particular product is small. 
Speci.cally, this paper has the following main contribu.tions: 
1. 	
The authors adopt the usage of the co-word network in a product design context. The co-word network has shown to be useful in multiple semantic extraction applications in information retrieval literature [7, 18]. To the best of our knowledge, this technique has .rst been used in the design literature. 

2. 	
The authors propose a probabilistic mathematical model in order to map implicit product-related information in social media data into the equivalent explicit context. 

3. 	
The authors illustrate the ef.cacy of the proposed method.ology using a case study of real world smartphone data and Twitter data. 




2 	Related Works 
While the use of implicit language such as indirect speech and sarcasm has been well explored in multiple psycholinguis.tic studies [19–21], automatic semantic interpretation of im.plicit information in social networks is still in an infancy stage. This section .rst surveys the use of social media data pertain.ing to the product design applications, and then discusses ex.isting natural language processing techniques that have been used to extract semantics from social media data. 

2.1 	Applications of Large Scale Social Media Data in Product Design Domain 
Knowledge extracted from product-related, user-generated information has proved valuable in product design applications. Archak et al. proposed a set of algorithms, both fully automated and semi-automated, to extract opinionated product features from online reviews. The extracted informa.tion was successfully used to predict product demand [22]. While their .ndings were promising, the algorithms were applied on online product reviews whose nature is different from social media data, in terms of noise, amount of indirect language (i.e. sarcasm), and language creativity that do not conform to the standard English grammar. This research primarily aims to interpret semantics of a subset of social media data whose language is presented with sarcasm, that traditional natural language processing techniques would fail to handle effectively. Social media has recently been established as a viable source for product design and develop.ment. Previous studies claimed that knowledge extracted from social media data could be more bene.cial than traditional product design knowledge sources such as product reviews (from popular online electronic commerce website such as Amazon.com, BestBuy.com, Walmart.com) and user study campaigns [2, 4, 5]. Asur et al. was able to use Twitter data collected during a 3 month period to predict the demand of theatre movies [23]. They claimed that the prediction results are more accurate than those of the Hollywood Stock Exchange. Their study also found that sentiments in tweets can improve the prediction after a movie has been released. Tuarob and Tucker found that social media data could be a potential data source for extracting user preferences towards particular products or product features [2, 5]. In a later work, they presented a methodology for automatic discovery of innovative users (aka. lead users) in online communities, using a set of mathematical models to extract latent features (product features not yet implemented in the market space), then identify lead users based on the volume of innovative fea.tures that they express in social media [1, 4]. Lim and Tucker proposed a Bayesian-based statistical sampling algorithm that identi.es product-feature-related keywords from social media data, without human-labeled training data [6]. Recently, Stone and Choi presented a visualization tool which allows designers to extract useful insights from online product reviews [24]. 

Since all the above techniques rely on the assumption that social media data is explicit, these techniques would fail to cor.rectly process implicit social media messages which could re.sult in error or inaccurate results. With these emerging product design applications that rely on social media as a knowledge source, it is crucial that the algorithms behind these applica.tions are able to correctly interpret the true meaning of the data. 

2.2 	Natural Language Technology for Semantic Interpre.tation in Social Media 
In this subsection, technologies used to process social me.dia data that go beyond just keyword detection (which works only on explicit data) are reviewed. Multiple studies in the In.formation Retrieval .eld have agreed that it is necessary to de.velop special text processing techniques for social media mes.sages, since they are different from traditional documents due to smaller textual content, heterogeneous language standards, and higher level of noise [25–29]. 
Social media holds sentiments expressed by its users (pri.marily in the form of textual data). Sentiment analysis in so.cial media refers to the use of natural language processing, text analysis and computational linguistics to identify and extract 
subjective information in social media. Thelwall et al. found 3 Methodology 
that important events lead to increases in average negative sen.timent strength in tweets during the same period [30]. The authors concluded that negative sentiment may be the key to popular trends in Twitter. Kucuktunc et al. studied the in.u.ence of several factors such as gender, age, education level, discussion topic, and time of day on sentiment variation in Ya.hoo! Answers [31]. Their .ndings shed light towards an ap.plication on attitude prediction in online question-answering forums. Weber et al. proposed a machine learning based algo.rithm to mine tips, short, self-contained, concise texts describ.ing non-obvious advice [32]. Lim et al. applied unsupervised sentiment analysis in social media to identify the patient’s po.tential symptoms and latent infectious diseases [9]. Sentiment of each short text is extracted and used as part of the features. Even though sentiment analysis could prove to be useful when designers would like to know how customers feel about a par.ticular product or product feature, most sentiment extraction techniques only output sentiment level in two dimension (i.e. Positive and Negative). Hence, more advanced techniques are needed in order to narrow down what actually the customers want to say. 
Besides sentiment analysis, multiple studies have found that topical analysis could be useful when dealing with noisy textual data such as social media. Even though social media is high in noise due to the heterogeneity of the writing styles, formality, and creativity, such noise bears undiscovered wis.dom of the crowd. Paul and Dredze utilized a modi.ed Latent Dirichlet Allocation [33] model to identify 15 ailments along with descriptions and symptoms in Twitter data [34, 35]. Tu.arob et al. proposed a methodology for discovering health re.lated content in social media data by quantifying topical simi.larity between documents as a feature type [7,8]. Furthermore, a number of studies have devoted to using topical models to de.tect emerging trends in social networks [36–38]. In the design informatics .eld, Tuarob and Tucker proposed a set of methods that extract product related information from large scale social media data, such as customer demands, notable product fea.tures, and innovative product ideas [1, 2, 39]. The techniques mentioned above rely on explicit content of social media data and would likely fail or not produce correct results when ap.plied on documents whose meanings are implicit. 
Implicit document processing has posed challenges to computational linguists. Researchers have studied on the na.ture of implicit uses of language; however, none have suc.cessfully developed a computational model to translate implicit content into the equivalent explicit form. In dealing with im.plicit context in social media data, multiple algorithms have been proposed to detect the presence of implicit content in so.cial media [16,40,41]; however, these algorithms do not further attempt to map the implicit content to the equivalent explicit forms. To the best of our knowledge, we are the .rst to ex.plore the problem of identifying explicit customer preferences towards a product/product feature from large scale social me.dia data. 

The method proposed in this paper mines language us.ages in the form of word co-occurrence patterns, in order to map implicit context commonly found in social media data to equivalent explicit ones. Figure 1 outlines the overview of the proposed methodology. 

Fig. 1. Overview of the proposed system. 

First, social media data is collected and preprocessed (Sec.tion 3.1). The textual content is then fed to the indexer in or.der to generate the co-word network (Section 3.2). Once the network is generated and indexed, the user could give the sys.tem an implicit message as the query. The query is processed and the results are returned to the user as a ranked list of rel.evant keywords classi.ed by parts of speech (Section 3.4). In this system, the user could be a human designer, or an auto.mated program that mines product related information from social media messages. 
A practical usage of the proposed implicit message infer.ence system would be to aid designers in synthesizing product features, mined from customers’ feedback in large scale social media data, into the next generation products. A framework was presented in [2], where designers iteratively identify no.tably good and bad features from existing products, and incor.porate/remove them from the next generation products. The method proposed in this paper could be incorporated into such a framework to improve the notable product feature extraction process. The following subsections will discuss each compo.nent in Figure 1 in detail. 
3.1 Social Media Data Preprocessing 
Social media provides a means for people to interact, share, and exchange information and opinions in virtual com.munities and networks [42]. For generalization, the proposed methodology minimizes the assumption about functionalities of social media data, and only assumes that a unit of social media is a tuple of unstructured textual content, a user ID, and a timestamp. Such a unit is referred to as a message throughout the paper. This minimal assumption would allow the proposed methodology to generalize across multiple het.erogeneous pools of social media such as Twitter, Facebook, Google+, etc., as each of these social media platforms has this common data structure. Social media messages, corresponding to each product domain, are retrieved by a query of the prod.uct’s name (and its variants) within the large stream of social media data. 
3.1.1 Data Cleaning 
Most social media crawling APIs provide additional infor.mation with each social media message such as user identi.ca.tion, geographical information, and other statistics 1. Though this additional information could be useful, it is disregarded and removed not only to save storage space and improve com.putational speed, but also to preserve the minimal assumption about the social media data mentioned earlier. 
Raw social media messages are full of noise that could prevent further steps from achieving the expected performance. In order to remove such noise, the data cleaning process does the following: 
1. 
Lowercasing the textual content 

2. 
Removing hashtags, usernames, and hyperlinks 

3. 
Removing stop words2 


Note that misspelled words (e.g. hahaha, lovin, etc.) and emoticons (e.g. :-), (")(--)("), etc.) are intention.ally preserved. Even though they are not well-formed and do not exist in traditional dictionaries, they have been shown to carry useful information that infers semantic meaning behind the messages [8, 43]. Furthermore, unlike traditional prepro.cessing techniques for reducing noise in documents, the social media data is not stemmed, since previous studies have shown that stemming could excessively reduce the dimensionality of the data (especially in short messages, each of which contains roughly 14 words on average [44, 45]), and would likely result in poorer performance [7]. 


3.1.2 Sentiment Extraction 
The technique developed by Thelwall et al. is employed to quantify the emotion in a message [43]. The algorithm takes a short text as an input, and outputs two values, each of which ranges from 1 to 5. The .rst value represents the positive sen.timent level, and the other represents the negative sentiment level. The reason for having the two sentiment scores instead of just one (with ./+ sign representing negative/positive sen.timent) is because research .ndings have determined that posi.tive and negative sentiments can coexist [46]. However, in this research, we only focus on the net sentiment level; hence, the 
1https://dev.twitter.com/rest/public 
2Stop words are words that are .ltered out before processing of textual information. Such words are typically too common to infer meaningful se.mantics. Examples of stop words include the, is, at, which, and on. 


positive and negative scores are combined to produce an emo.tion strength score using the following equation: 
Emotion Strength(ES)= PositiveScore . NegativeScore (1) 

A message is then classi.ed into one of the 3 categories based on the sign of the Emotion Strength score (i.e. positive (+ve), neutral (0ve), negative (-ve)). The EmotionStrength scores will later be used to identify whether a particular mes.sage conveys a positive or negative attitude towards a particular product or product feature. 
3.1.3 Feature Extraction. 
Algorithm 1: The feature extraction algorithm from a collection of documents  
Input: D: Set of free-text documents to extract product features. Output: E: Set of extractions. Each e . E is a tuple of (f eature, f requency), for example e = (‘onscreen keyboard. , 5) 1 preprocessing; 2 for d . D do 3 Clean d ; 4 POS tag d ; 5 Extract multi-word features ; 6 end 7 initialization; 8 E = . ; 9 T = . ; 10 F = Seed Features ; 11 while E can still grow do 12 Learn templates from seed features; 13 Add new template to T; 14 foreach d . D do 15 foreach Sentence s . d do 16 e  Extract potential feature-opinion pair using T; 17 Add e to E ; 18 end 19 end 20 Update F; 21 end 22 E  Clustering and normalizing features ; 23 return E;  

Product features are extracted from each social media message. In this paper, the feature extraction algorithm used in [4] is employed. The pseudo-code of the algorithm is out.lined in Algorithm 1. At a high level, the algorithm takes a collection of social messages corresponding to a product as input, and outputs a tuple of (f eature, f requency) such as (‘onscreen keyboard. , 5), which infers that the on-screen key.board feature of this speci.c product was mentioned 5 times within the given corpus of social media messages. Interested readers are encouraged to consult [4] for additional details about the feature extraction algorithm. 
The features are extracted because the proposed method.ology infers explicit opinions towards a particular product fea.ture, hence it is imperative that product features can automati.cally be identi.ed. 


3.1.4 Part of Speech Tagging. 
Table 1. Node types and their descriptions. 
Node Type  Descripton  
PRODUCT  Smartphone model name  
N  common noun  
A  adjectve  
V  verb including copula, auxiliaries  
^  proper noun  
!  interjecton  
P  pre-or postpositon, or subordinatng conjuncton  
G  other abbreviatons, foreign words, possessive endings, symbols, garbage  
R  adverb  
L  nominal + verbal (e.g. i’m ), verbal + nominal (let’s )  
D  determiner  
~  discourse marker, indicatons of contnuaton across multple tweets  
E  emotcon  
O  pronoun (personal/WH; not possessive)  
$  numeral  
,  punctuaton  
&  coordinatng conjuncton  
Z  proper noun + possessive  
T  verb partcle  
S  nominal + possessive  
X  existental there , predeterminers  

The .nal step of the social media data preprocess is to tag each word in a social message with a part of speech (POS). In this paper, Carnegie Mellon ARK Twitter POS tagger3 is used for this purpose. This particular POS tagger has not only been developed specially for social media data, but has also been successfully used in the product design domain [2]. 
The part of speech information is needed in or.der to disambiguate words with multiple meanings (i.e. homonyms) [47], which can be commonly found in social media. For example, the word “cold” in “Who waits for an iphone5 in this cold weather?” and “I’ve got a cold this morning. will skip class.” may have different meanings. 
Each POS tag will become a node type in the co-word network. Besides standard linguistic POS tags offered by the 
3http://www.ark.cs.cmu.edu/TweetNLP/ 

POS tagger tool, a special node type PRODUCT is also in.troduced to distinguish a word that represents a product name 
(e.g. iPhone 4, Samsung Galaxy SII, Nokia N9, etc) from other words. Table 1 lists the node types used in this research, along with their descriptions. 


3.2 Generating and Indexing Co-word Network 
A co-word network is the collective interconnection of terms based on their paired presence within a speci.ed unit of text. Traditional co-word networks represent a node with only textual representation of a word. Variants of co-occurrence networks have been used extensively in the Information Re.trieval .eld in a wide range of applications that involve se.mantic analysis such as concept/trend emergence detection [48, 49], discovering new words, .nding/clustering relevant items [50, 51], semantic interpretation [7, 52], and document annotation [53, 54]. 
In this paper, a node also incorporates part of speech infor.mation for word-sense disambiguation purposes. Concretely, a co-word network is an undirected, weighted graph where each node is a pair of (Word, POS Tag) (e.g., (squint,V) and (iPhone 4, PRODUCT)) that represents a POS tagged word, and each edge weight is the frequency of co-occurrence. Let D be the set of all social media messages, and T be the vocab.ulary extracted from D. Formally, the co-word network G is de.ned as follows: 
G= (V,E) 
V={(Word, POS Tag). T } 
E={(a,b)| a,b . T} 
Weight(a,b)=|{d | d . D, (a,b). E, d contains both a 
and b}| 

A compound is de.ned as a set of nodes. A social media message is converted to a compound by converting each word in the message into a node. The nodes are then combined. Replicated nodes are removed. Algorithm 2 explains how the co-word network is generated from a corpus of social media messages. First, the set of nodes, V , and the set of edges, E, are initialized to empty sets. For each social media message d in the corpus D, all the words are tagged with appropriated POS tags, and then converted into nodes which are then combined into a compound c. For each node n in the compound c, update V by including n. Then for each possible combination pair of nodes in c, the weight of the edge that links these two nodes is incremented by 1. The co-word network generation is .nished once all the messages are processed. In this paper, the open-source graph database Neo4J4 is used to store and index the network. Neo4J is used in this task due to its scalability that allows a network with millions of edges to be ef.ciently stored and indexed. 
4http://neo4j.com/ 
Algorithm 2: The co-word generation algorithm from a collection of social media messages.  
Input: D: Set of free-text social media messages. Output: G: Co-word network. 1 initialization; 2 V = . ; 3 E = . ; 4 foreach Document d . D do 5 /*Extracting nodes from message*/ ; 6 Compound c = . ; 7 foreach Word w . d do 8 Node n = (w.text, w. pos) ; 9 Add n to c ; 10 end 11 /* Update V */ ; 12 foreach Node n . c do 13 if n /. V then 14 Add n to V ; 15 end 16 end 17 /* Update E */ ; 18 foreach Possible combination of word pair (a, b) in D do 19 Edge e = (a,b) ; 20 if e /. E then 21 Add e to E ; 22 end 23 Increment e.weight by 1 ; 24 end 25 end 26 return G = (V, E);  



3.3 Sarcasm Detection 
A majority of implicit social media data is manifested in the form of sarcastic messages. Maynard and Greenwood reported that roughly 22.75% of social media data is sarcas.tic [14]. Hence, this work focuses on improving the ability to interpret sarcastic product related social media messages. In the proposed framework, sarcastic messages are automatically discovered using a machine learning based sarcasm detection algorithm, implemented in [55]. The algorithm produces a sar.castic message detection model using the features extracted from the training data. These feature sets include: 
N-grams: This feature set extracts individual words (uni.grams) and two consecutive words (bi-grams) from a given message. These n-gram features are used exten.sively to train classi.cation models for text classi.cation tasks. Three and more consecutive words are not used since research has shown the combination of uni-grams and bi-grams are suf.cient and optimal, that yields the best results while consuming reasonable amounts of com.puting resources and memory [56]. Sentiment: It is a hypothesis that sarcastic messages are more negative than non-sarcastic ones. Mathematically, 
h0: sentimentneg(sarcastic) > sentimentneg(non sarcastic) 
(2) Moreover, studies show that sarcastic messages tend to ex.hibit the co-existence of positive and negative sentiments [46]. The sentiment features include 1.) a positive and a negative sentiment score to each word in the message us.ing the SentiWordNet5 dictionary, and 2.) the sentiment score produced by the python library TextBlob6. Topics: The topical features are extracted using the Latent Dirichlet Allocation algorithm [33] implemented in gen.sim7. 

The training dataset includes 20,000 sarcastic tweets and 100,000 non-sarcastic tweets over a period of three weeks in June-July 2014. Once the features are extracted from the train.ing data, they are used to train a support vector machine (SVM) classi.cation model. The trained model is then used to identify a message whether it is sarcastic or non-sarcastic. 

3.4 Query and Result Processing 
A query is a free text message with implicit content. Example queries include “I can’t express how much I love the price of iPhone 5 on black Friday” and “I have to squint the screen to read this on Nokia N9”. This section describes how a user query is transformed into the network-compatible format, or a compound Q, for further processing. In particular, in order to process a free text query QText , the following steps are performed: 
1. 	
Preprocess the query QText using the mechanism described in Section 3.1, in order to clean the raw message, extract features, and assign POS tags. 

2. 	
Form the query compound Q, by converting each POS tagged word into a node, and combining them into a set. 

3. 	
Remove the nodes in Q that do not exist in the co-word network. 



The resulting query compound Q is then fed into the sys.tem for further processing. 
The implicit message translation problem in transformed into a node ranking problem so that traditional Information Re.trieval techniques can be applied. In this context, a node in the co-word network is equivalent to a combination of a word and its POS. Given the set of products in the same domain (product space) S, the set of all features (feature space) F, the co-word network G = (V, E), and query compound Q. The node ranking algorithm takes the following steps: 
STEP1 	For each node t . V , compute P(t|Q, f , s), the likeli.hood (relevant to product features) of the node t given the 
5http://sentiwordnet.isti.cnr.it/ 
6https://textblob.readthedocs.io/en/dev/ 
7https://radimrehurek.com/gensim/ 

query compound Q, target product feature f . F, and the 
product s . S. STEP2 Rank the nodes by their likelihood. STEP3 Top nodes are returned. 
P(t|Q, f , s) represents the likelihood that the node t is rel.evant to the feature f of the product s, given the query com.pound Q. The relevance of a node is quanti.ed by its related.ness and explicitness to the query compound Q. Hence, math.ematically P(t|Q, f , s) is de.ned as follows: 
P(t|Q, f , s)= . wq . Relatedness(t, q) . Explicitness(t|q) q.Q 
(3) Where, 
weight(t,q)
Relatedness(t, q)= (4) 
.n.Ad j(q) weight(n,q) degree(t)
Explicitness(t|q)= (5) 
.n.Ad j(q) degree(n) 
wq is the weight for the node q . Q, and .q.Q wq = 1. Ad j(q) is the set of adjacent (neighbor) nodes to q. In the implementation, feature (i.e. f ) and product nodes (i.e. s) are given twice the weight of other nodes in the compound. This is because, by giving higher weight to the target feature and prod.uct, the likelihood given to each node will be more relevant to.wards the feature of the product of interest. weight(t, q) is the weight of the edge linking t and q, which is the co-occurrence frequency of the two nodes. Note that if t and q have never been mentioned together, then the Relatedness(t, q) is evalu.ated to zero. 
Relatedness(t, q) hence quanti.es how frequently t and q are mentioned together. The score is normalized to range be.tween [0,1] for consistency when combined with other compo.nents. 
Explicitness(t|q) quanti.es explicitness of the term repre.sented by the node t when presented in the same context as the term represented by the node q, and is measured by the nor.malized degree of the node t. A term is explicit if it makes the context clearer or easier to understand to the readers. An intu.itive assumption is made that terms that have explicit meanings tend to be commonly used and mentioned frequently in multi.ple contexts. Such properties are captured by the degree of the node representing the term, since the higher degree a node has, the more diverse it is co-mentioned with other words. Table 2 provides examples of 10 highest degree nodes and 10 lowest degree nodes, classi.ed by parts of speech. From the exam.ple, it can be seen that words with high degrees have explicit meanings and would make the context simpler and more clar.i.ed. On the other hand, the words with low degrees tend to be spurious words that do not directly associate with the prod.uct domain. These words tend to make the context implicit, especially when talking about a product or product feature. 
Finally, P(t|Q, f , s) is then a weighted sum of the rele.vance between the node t . V and each node in the query com.pound Q. P(t|Q, f , s) ranges between [0,1], using to approxi.mate the probability of the node t being relevant to the query compound q. Once P(t|Q, f , s) is computed for all the nodes in the co-word network, they can then be ranked using this score. The .nal output of the system would then be the top words classi.ed by their parts of speech. 

4 Case Study, Results, and Discussion 
This section introduces a case study used to verify the pro.posed methodology and discusses the results. 
A case study of 27 smartphone products is presented that uses social media data (Twitter data) to mine relevant prod.uct design information. Data pertaining to product speci..cations from the smartphone domain is then used to validate the proposed methodology. The selected smartphone mod.els include BlackBerry Bold 9900, Dell Venue Pro, HP Veer, HTC ThunderBolt, iPhone 3G, iPhone 3GS, iPhone 4, iPhone 4S, iPhone 5, iPhone 5C, iPhone 5S, Kyocera Echo, LG Cos.mos Touch, LG Enlighten, Motorola Droid RAZR, Motorola DROID X2, Nokia E7, Nokia N9, Samsung Dart, Samsung Ex.hibit 4G, Samsung Galaxy Nexus, Samsung Galaxy S 4G, Sam-sung Galaxy S II, Samsung Galaxy Tab, Samsung Infuse 4G, Sony Ericsson Xperia Play, and T-Mobile G2x. 
Smartphones are used as a case study in this paper be.cause of the large volume of discussion about this product do.main in social media. Previous work also illustrated that social media data (i.e. Twitter) contains crucial information about product features of other more mundane products such as au.tomobiles [2,39]. The proposed algorithms may not work well for products which are not prevalently discussed (in terms of quantity of messages related to the product) in social media as the corresponding sets of social media messages may be too small to extract useful knowledge from. 
4.1 Social Media Data Collection 
Twitter8 is a microblog service that allows its users to send and read text messages of up to 140 characters, known as tweets. The Twitter dataset used in this research was col.lected randomly using the provided Twitter API, and comprises 2,117,415,962 (. 2.1 billion) tweets in the United States during the period of 31 months, from March 2011 to September 2013. 
Tweets related to a product are collected by detecting the presence of the product name (and variants), and preprocessed by cleaning and mapping sentiment level as discussed in Sec.tion 3.1. Table 3 lists the number of tweets, number of unique Twitter users, and number of extracted features. 

4.2 Co-word Network Generation 
The co-word network is generated using the procedure outlined in Algorithm 2, using all the social media data asso.ciated with the 27 smartphone models. The resulting network contains 95,999 nodes and 2,288,723 edges. A node has a de.gree of 47.7 and is used 160 times on average. Table 4 lists the 
8https://twitter.com/ 

Table 2. (Left) Top 10 nodes (words) with highest degree, classi.ed by parts of speech. (Right) Bottom 10 nodes (words) with lowest degree, classi.ed by parts of speech. 
Highest degree nodes (words)  Lowest degree nodes (words)  
N  V A !  N V A  !  
phone case today .me day screen people app charger camera  got good lol need free haha buy great ya wait cool yeah love bad lmao gonna nice wow make long hey upgrade happy damn sell big yo feel fast omg  synergy obstruct conten.ous granddaddy expel uncomplicated seeds con.gure sowable average cook disconnected pervert violate democra.c hugs deploy doub.ul orphan redirect inappropriate swimsuit bleed prac.camente chau.eur impersonate unrecoverable paradigm reign heartbroken  heeh ofan wordddd soz lololololol eiiishhh yayayayay wujuuu oooou naaaaaw  

Table 3. Statistics of the Twitter data used in this paper, classi.ed by smartphone products. See Appendix A for explanation of each statistic. 
Model  Num Tweets  Num Users  Num Features  Feature Utlizaton  Feature Intensity  Average Feature Diversity  
BlackBerry Bold 9900  308  252  126  1.7460  0.7143  0.0219  
Dell Venue Pro  96  64  50  1.8800  0.9792  0.0380  
HP Veer  143  110  76  1.7632  0.9371  0.0265  
HTC ThunderBolt  1157  851  335  2.5522  0.7390  0.0071  
iPhone 3G  2154  1874  532  2.8459  0.7029  0.0050  
iPhone 3GS  3803  3119  775  3.0361  0.6187  0.0041  
iPhone 4  68860  43957  6057  5.2196  0.4591  0.0010  
iPhone 4S  63500  39145  5922  6.0750  0.5666  0.0010  
iPhone 5  211311  124461  13493  7.8739  0.5028  0.0006  
iPhone 5C  5533  4475  833  5.1477  0.7750  0.0046  
iPhone 5S  15808  12417  1962  5.9210  0.7349  0.0023  
Kyocera Echo  52  42  22  1.3636  0.5769  0.0877  
LG Cosmos Touch  23  20  11  1.4545  0.6957  0.1313  
LG Enlighten  18  17  5  1.6000  0.4444  0.2000  
Motorola Droid RAZR  2535  1981  593  3.4840  0.8150  0.0056  
Motorola DROID X2  471  378  162  2.1790  0.7495  0.0134  
Nokia E7  26  18  14  1.2143  0.6538  0.0879  
Nokia N9  208  153  83  1.7470  0.6971  0.0224  
Samsung Dart  29  28  10  1.5000  0.5172  0.1071  
Samsung Exhibit 4G  23  22  10  1.2000  0.5217  0.1333  
Samsung Galaxy Nexus  5218  2988  1147  3.2476  0.7139  0.0031  
Samsung Galaxy S 4G  188  152  62  2.0161  0.6649  0.0293  
Samsung Galaxy S II  4599  3517  801  3.1436  0.5475  0.0042  
Samsung Galaxy Tab  3989  2578  884  3.1912  0.7072  0.0033  
Samsung Infuse 4G  284  215  85  2.2000  0.6585  0.0192  
Sony Ericsson Xperia Play  481  325  132  1.9394  0.5322  0.0148  
T-Mobile G2x  83  69  39  1.4359  0.6747  0.0351  

numbers and average degrees of nodes categorized by parts of speech. 
Figure 2 illustrates a graphical visualization of the gener.ated co-word network using the large-scale graph layout gen.eration algorithm OpenORD [57]. 


4.3 Query and Result Processing 
This section reports notable results from the proposed methodology. 
Given a textual query with implicit content, the sys.tem .rst transforms it into a compound, by removing stop words and converting each remaining distinct word into a node. For example, a textual query “I have to squint 


Fig. 2. Graphical visualization of the generated co-word network. 

Table 4. Statistics of the co-word network generated using the Twitter data associate with the 27 smartphone products. The number of nodes and average degrees are categorized by the types of nodes. 
Node Type  # of Nodes  Avg Degree  Node Type  # of Nodes  Avg Degree  
PRODUCT  27  4589.17  ~  92  22.63  
N  24931  56.79  E  88  35.73  
A  6169  64.93  O  452  50.16  
V  13508  62.11  $  25  79.56  
^  32562  30.62  ,  35  20.43  
!  4566  39.46  &  62  55.50  
P  840  57.13  Z  90  15.47  
G  9354  38.30  T  42  11.00  
R  2325  48.09  S  25  10.28  
L  432  66.48  X  13  16.38  
D  361  79.07  


the screen to read this on Nokia N9” would be translated into the compound {(read,V ), (squint,V), 
RZQHUV1  
ODQJ*  
MREV1  
KDKDK  
VZHDU9  
KRXVHA  SURGXFW1  VDYH9  KDKDKDKD  ORFNHG9 MDLOEUHDN1 XSGDWLQJ9 \D'  UHDG9  
DSULOA  
FKDUJLQJ9  SLFNHG9  VLPA  VFUHHQV1  
XU/  TXLFN$  
ZRUNLQJ9  VFUDWFKHV1  ILQDOO\5KPP ODWH$ EXVLQHVV1 UD]U1 L3KRQH352'8&7  
SD\9  JODVV1  

DOULJKW  LP/ KROG9 KRPH1 UHDG\$ MDLOEURNHQA  
UHYLHZV1  
EXWWRQV1  VFUHHQ1  FRPLQJ9 IDVW$ VWRUH1 \HDK ELJ$ DSSV1 SKRWR1 VTXLQW9 NLQG1 QHHG9  
SULFHV1 VWRUHA 1RNLD1352'8&7  
ZRUVH$  
ZLIL1  SDUD*  QHHG1  IRUJHW9 DSSOHA SDJH1 OHDYLQJ9  
SUHRUGHUV1  

L3KRQH352'8&7 
ILQQD9 

XP 
PHVHV1 
GHDWK1 
WXHVGD\A 
MXV5 
MRE1 
GLH9 
LLLA 

Fig. 3. Graphical example of the words co-occurring with the query compound. 
(screen, N), (Nokia N9, PRODUCT)}. Note that not all the words in the query are converted into nodes since they could be stop words (e.g., I, have, the, this, and on). Figure 3 shows part of the generated co-word network where all the nodes co-occur with the queries nodes (red nodes). The thickness of the edges are proportionate to the actual edge weight. Similarly, the size of each node represents its relative degree. 
4.3.1 Experiment Procedure 
Product  # Negatve # Neutral # Positve  All  
HTC ThunderBolt  5  4  4  13  
Motorola Droid  4  20  11  35  
Samsung Galaxy  22  46  20  88  
iPhone 3  7  15  3  25  
iPhone 5  34  95  47  176  
iPhone 4  35  38  52  125  
Avg  17.83  36.33  22.83  77  

Table 5. Number of tweets, categorized by hand-labelled sentiment (Negative, Neutral, Positive), associated with each selected smart-phone model. 
Six smartphone models are selected for evaluation of the proposed co-word implicit message translation model, including HTC ThunderBolt, Motorola Droid, Samsung Galaxy, iPhone 3, iPhone 5, iPhone 4. The sarcasm detection algorithm described in Section 3.3 is used to select sarcastic messages associated with each select smartphone model. To establish ground-truth validation data, each message (and the focus product feature) is manually tagged with actual sentiment (negative, neutral, or positive) of the message poster towards such a feature. For example, “I love how everyone with an iPhone 5 says ‘look! My camera is 8 megapixels.’ No. F*** off. Both of my Evo’s have had 8 megapixel camera’s.” is associated with iPhone 5, and is tagged with (camera, Negative), meaning that the poster may actually feel negative (i.e. unsurprised) about the camera feature of the iPhone 5. Table 5 list the number of sarcastic messages, manually classi.ed by its actual sentiment, associated with each selected smartphone model. 

The evaluation is designed to compare the performance between the proposed co-word implicit message translation model (Co-word) against a baseline (Baseline). The base.line method returns the original sarcastic message without any modi.cation (hence, the message is not semantically processed with the co-word network shown in Figure 1). Such compari.son would allow us to see if the proposed Co-word model could translate a given sarcastic message into its explicit form. To compare the ef.cacy of both methods, this problem is trans.formed into a classi.cation problem, where both the Co-word and Baseline translated versions are classi.ed based on the sen.timent (Negative, Neutral, Positive) using the sentiment extrac.tion algorithm described in Section 3.1.2, and compared with the ground truth actual sentiment. Standard information re.trieval evaluation metrics are used, including precision, recall, and F-measure. These metrics have been used extensively to validate the quality of the results of classi.cation algorithms [58]. 

For each sentiment class c .{Negative, Neutral, Posi.tive}, let CC(c) denote the number of sarcastic messages cor.rectly classi.ed as c, CA(c) denote the number of sarcastic messages classi.ed as c, and N(c) denote the number of sar.castic messages labelled as class c, these metrics are de.ned as follows: 
CC(c)
precision(c)= (6) 
CA(c) 

CC(c)
recall(c)= (7) 
N(c) 
precision(c) . recall(c)

F . measure(c)= 2 . (8) 
precision(c)+ recall(c) 

Recall is the ratio of a number of messages the classi.er can correctly recall to a number of all messages in that class. If there are 10 messages that belong to the class c, and a clas.si.er can recall all 10 messages correctly, then the recall of the 0.80 
Baseline Co-word 

classi.cation with respect to class c is 1.0 (100%). If the clas-0.70 0.63 
Fig. 5. Comparison of F-measure evaluation of the class Negative, for each selected smartphone model. 

si.er can recall 7 messages correctly, then the recall ratio is 
0.56 
0.55 
0.60 
F-measure (Negatve) 
0.7 (70%). Precision is the ratio of a number of messages the 
0.47 0.46 
0.46 
0.44 
0.50 
0.41 
classi.er correctly recalls to a number of all messages it recalls 
0.40 0.33 0.33 
(mix of correct and wrong recalls). In other words, precision 
0.25 
0.23 
0.30 
quanti.es how precise of the recalled results. F-measure com.
bines precision and recall into one number with equal weights. 
0.20 
Note that, precision, recall, and F-measure range from [0,1]. 

4.3.2 Experiment Results 
Table 6 reports the sentiment classi.cation results from the messages translated by the co-word method and the baseline for each select smartphone model. The classi.cation results for each class (Positive, Neutral, Negative) of both the meth.ods are displayed. The bold .gures denotes the better result 
0.10 
0.00 
HTC Motorola Samsung iPhone 3 iPhone 5 iPhone 4 ThunderBolt Droid Galaxy 
Product 


each selected smartphone model. 
between the co-word and the baseline methods. Figure 4 sum.marizes the classi.cation performance of the six select smart-phone models, grouped by precision, recall, and F-measure of the three sentiment classes. 
Figure 5 emphasizes the comparison between the F-measure of the classi.cation results of sarcastic messages translated by the co-word and the baseline methods. The mes.sages translated by the proposed co-word method improves the sentiment extraction algorithm to identify the true negative sentiment for four out of six products, namely Motorola Droid, iPhone 3, iPhone 5, iPhone 4. The reason why the co-word method performs worse than the baseline could be explained by Figure 4. For negative class, though the overall recall of the co-word method surpasses that of the baseline by +39.46%, the precision suffers from the deterioration of -21.21%. This 
phenomenon suggests that the co-word method still misinter.prets some of the actual positive messages as negative (since 

the recall for the positive class also drops by -34% according Figure 6 compares the F-measure of the co-word and to Figure 4), and hence introduce false positives to the senti-baseline of the neutral class. Evidently, the proposed co.ment classi.er. Regardless, the overall performance in terms word method allows the sentiment classi.er to correctly in-of F-measure is improved by 14% for the negative class. terpret the actual neutral sentiment of a sarcastic message in 
Method  Baseline  Co-word  
Class  Negatve (-)  Neutral (0)  Positve (+)  Negatve (-)  Neutral (0)  Positve (+)  
Product  P  R  F  P  R  F  P  R  F  P  R  F  P  R  F  P  R  F  
HTC ThunderBolt  1.00  0.20  0.33  0.25  0.50  0.33  0.50  0.50  0.50  0.23  0.22  0.23  0.52  1.00  0.69  0.30  0.34  0.32  
Motorola Droid  0.25  0.50  0.33  0.33  0.20  0.25  0.20  0.27  0.23  0.46  1.00  0.63  0.84  0.81  0.82  0.34  0.32  0.33  
Samsung Galaxy  0.48  0.45  0.47  0.54  0.41  0.47  0.31  0.50  0.38  0.38  0.44  0.41  0.73  0.84  0.78  0.56  0.38  0.45  
iPhone 3  0.50  0.42  0.46  0.75  0.40  0.52  0.18  0.67  0.29  0.41  0.53  0.46  0.78  0.78  0.78  0.34  0.33  0.34  
iPhone 5  0.23  0.26  0.25  0.54  0.33  0.41  0.31  0.53  0.39  0.37  0.55  0.44  0.75  0.72  0.73  0.72  0.37  0.49  
iPhone 4  0.56  0.54  0.55  0.48  0.34  0.40  0.59  0.73  0.66  0.53  0.59  0.56  0.52  0.83  0.64  0.87  0.38  0.53  
Avg  0.50  0.40  0.40  0.48  0.36  0.40  0.35  0.53  0.41  0.40  0.55  0.45  0.69  0.83  0.74  0.52  0.35  0.41  

Table 6. Comparison of the classi.cation performance between the proposed co-word based method and the baseline (no translation process), for each sentiment class. P denotes Precision, R denotes recall, and F denotes F-measure. 
all the select six smartphone models. Figure 4 further elabo.rates this phenomenon by showing the improvement in preci.sion (by +42.57%), recall (by +128.24%), and F-measure (by +86.46%). 

Fig. 7. Comparison of F-measure evaluation of the class Positive, for each selected smartphone model. 
Figure 7 compares the F-measure of both the co-word and baseline of the sentiment classi.cation on the positive class. The co-word method improve the sentiment classi.cation in four out of six smartphone models including Motorola Droid, Samsung Galaxy, iPhone 3, and iPhone 5. The reason why the co-word method is not the clear winner for all the select prod.ucts for the positive sentiment messages is because the co-word technique still tends to misinterpret some of the positive senti.ment messages as negative ones. As a result, the amount of the translated messages that appear to be positive is limited, caus.ing a drop in recall of -34% on average (according to Figure 4). Regardless, since the co-word method is selective about the positive class, the precision of the positive class is boosted by +49.15%, leading the F-measure of the positive class to im.prove by +2.78%. 
Overall, the classi.cation results in terms of F-measure are improved on average for all the three sentiment classes (+14% for positive class, +86.46% for neutral class, and +2.78% for positive class). The experiment results presented in this section not only illustrate that the co-word technique has the potential to facilitate the translation of implicit social media messages, so that they can be further processed by traditional natural lan.guage processing techniques, but also shed light on room to improve and extend this proposed framework for design appli.cations that rely on knowledge extracted from large scale social media data such as [1–3]. 

Table 7 illustrates the actual results from the proposed methodology on 10 sample social media messages whose pref.erences associated with the target product features are implicit 
(i.e. in the form of sarcasm). The table lists actual Twitter mes.sages, target features, manual interpretation (by the authors) and the resulting top 3 relevant keywords (out of 10 keywords returned by the system), classi.ed by parts of speech. Only nouns (N), verbs (V), and adjectives (A) are showed since the combination of these words are mostly suf.cient in order to interpret the explicit semantic behind each message. 
From the sample results, it is evident that the com.bination of the top words returned by the system could potentially provide explicit meaning of the implicit message. For example, the meaning behind “I can’t express how much I love the price of iPhone 5 on black Friday” may infer that the user would like to buy and iPhone 5 today (which may be a Black Friday) because the price is cheap. Similarly, the user who posts “eh DroidRazr HD resolution? I don’t think so.” may convey that the display of his/her Droid Razr is bad, and needs to be upgraded. 
Most traditional semantic interpretation techniques in.cluding sentiment analysis assume that documents are explicit, and would fail when dealing with these implicit social media messages. The Column “Sentiment Level (From Implicit Con.text)” shows quanti.ed sentiment level using the algorithm de.scribed in Section 3.1.2 on the original tweets. The actual Emo.tional Strength scores are in parentheses. The Column “Man.ual Sentiment Evaluation” lists the manual evaluation by the authors on the actual sentiment that each sample tweet infers towards the target product features (either Positive or Nega.tive). The Column “Sentiment Level (From Translated Explicit Context)” shows the sentiment level using the same sentiment extraction algorithm, but on the translated explicit content gen.erated by concatenating the top 20 keywords returned by the system into a single text (disregarding parts of speech). The sentiment levels computed on the translated text agree with the 
Table 7. Sample results of 10 sarcastic product-related tweets. 
Sample Number  Tweet  Target Product Feature  Manual Context Interpretaton  Manual Sentment Evaluaton  Sentment Level (From Implicit Context)  Explicit Translaton  Sentment Level (From Translated Explicit Context)  
Nouns  Verbs  Adjectves  
So the new #iPhone5s is getting a new "Home" button? Hmm...something #Android  The home buton feature  home buton  need lost  slow black  
1  phones have had for ages. Way to go #Apple! Way to innovate! Every time I see the Droid Razr commercial,  Home Buton  is not impressive.  Negatve  Neutral (0)  shit  sold  wrong  Negatve (-1)  
2  all I can think is, "You know what a great product doesn't need? Gimmicks." #apple #droidrazr Heard this from a Best Buy Mobile employee  Commercial  The comercial is not relevant. Adding Siri to  Negatve  Positve (2)  life batery gimmicks  make have hate  bad real funny  Negatve (-2)  
3  to a customer: "The only difference between the iPhone 4 and 4S is Siri." #impartial #informed Here's A Phone I Wouldn't Mind Getting-- Siri  iPhone 4S is not impressive. I want Nokia  Negatve  Positve (1)  day case shit case screen  wait need buy need want  big great bad good great  Negatve (-2)  
4  Nokia N9 That's so true! "if it looks the same how will people know I upgraded?" (iPhone 4 vs iPhone 4s)  Nokia N9  N9. iPhone 4s should have di.erent  Positve  Neutral (0)  camera people week  buy wait need  awesome good white  Positve (1)  
5  I can't express how much I love the price of  Looks  appearance from its predecessor.  Negatve  Positve (1)  shit today sale  hate need wait  free good free  Negatve (-1)  
6  iPhone 5 on black Friday I LOVE when my iPhone 5 charger stops  price  Price is cheap.  Positve  Neutral (0)  price  buy  cheap  Positve (3)  
7  working #deepsarcasm Have to use my moms iPhone eh DroidRazr HD resolution? I don't think so.  Charger  Charger is easily broken. Resoluton is  Negatve  Positve (2)  case iphone tme screen camera  hate borrow wait check sucks  stupid fast bad free sweet  Negatve (-2)  
8  "Samsung Galaxy S II Sprint Epic 4G Touch."  Resoluton  not HD. The name is not  Negatve  Neutral (0)  case  buying need make  slow  Negatve (-1)  
9  Yes that's a real name for a phone. Incredible. New iCloud? sounds a lot like the SkyDrive  Name  suitable. iCloud is not an  Negatve  Neutral (0)  galaxy day shit  sucks  bad fast true  Negatve (-1)  
10  that I used long before the iPhone 4s came out. Yay for Apple "innovation"  iCloud  innovatve feature.  Negatve  Positve (1)  lot photo tme  sounds need wait  cool bad crazy  Negatve (-1)  

manual evaluation in all the samples shown in Table 7. 
Not surprisingly, the sentiment level extracted from the original texts are all incorrect, since the sentiment extraction technique is designed to detect explicit sentiment, and hence would not give correct results when dealing with sarcasm or vague context. It is also interesting to note that the sentiment computed for the implicit sample messages tend to be neu.tral (Sentiment Level . 0), regardless of the fact that they are composed with emotion-inspired words (i.e., love, can’t, shit, beautifully, incredible, etc.). This agrees with prior .ndings that messages with implicit sentiment (i.e. sarcasm) would be sentimentally neutralized since such messages tend to have equally high volumes of both Positive and Negative scores, causing the Emotion Strength score to converge to 0 [59]. 




5 Conclusions and Future Works 
This paper proposes a knowledge based methodology for inferring explicit sense from social media messages whose connotations related to products/product features are implicit. The methodology .rst generates a co-word network from the corpus of social media messages, which is used as the knowl.edge source that captures the relationship among all the words expressed in the stream of large scale social media data. A set of mathematical formulations are proposed in order to iden.tify a combination of keywords that would best infer explicit connotation to a given implicit message query. A case study of real-world 27 smartphone models with 31 months’ worth of Twitter data is presented. The results of selected smart-phone models show great promises that the proposed method.ology is effective in translating implicit product preferences to their explicit equivalent connotation that could be readily used in further knowledge extraction applications such as syn.thesizing product features [2], predicting future product de.mands and long-term product longevity [5], and identifying in.novative users in online communities [4]. Future works could strengthen the evaluation process by involving user studies, and verify the generalizability of the proposed methodology by examining diverse case studies of different product domains and social media services. Machine learning approaches that process psychological information such as [60] will also be ex.plored to predict behaviors of customers from their sarcasm and other forms of language usages. 





Acknowledgements 
This research project is supported by Mahidol Univer.sity. Suppawong Tuarob is the corresponding author. We are also grateful for help with implementation and experimenta.tion from Lawrence Lee. 

References 
[1] Tuarob, S., and Tucker, C. S., 2015. “Automated discov.ery of lead users and latent product features by mining large scale social media networks”. Journal of Mechani.cal Design, 137(7), p. 071402. 
[2] Tuarob, S., and Tucker, C. S., 2015. “Quantifying product favorability and extracting notable product features using large scale social media data”. Journal of Computing and Information Science in Engineering, 15(3), p. 031003. 
[3] Tuarob, S., and Tucker, C. S., 2015. 	“A product feature inference model for mining implicit customer preferences within large scale social media networks”. In ASME 2015 International Design Engineering Technical Con.ferences and Computers and Information in Engineering Conference, American Society of Mechanical Engineers, pp. V01BT02A002–V01BT02A002. 
[4] Tuarob, S., and Tucker, C. S., 2014. 	“Discovering next generation product innovations by identifying lead user preferences expressed through large scale social media data”. In Proceedings of ASME International Design En.gineering Technical Conferences & Computers and Infor.mation in Engineering Conference 2014, ASME. 
[5] Tuarob, S., and Tucker, C. S., 2013. “Fad or here to stay: Predicting product market adoption and longevity using large scale, social media data”. In Proc. ASME 2013 Int. Design Engineering Technical Conf. Computers and In.formation in Engineering Conf.(IDETC/CIE2013). 
[6] Lim, S., and Tucker, C. S., 2016. 	“A bayesian sampling method for product feature extraction from large-scale textual data”. Journal of Mechanical Design, 138(6), 
p. 061403. 
[7] Tuarob, S., Tucker, C. S., Salathe, M., and Ram, N., 2014. “An ensemble heterogeneous classi.cation methodology for discovering health-related knowledge in social media messages”. Journal of Biomedical Informatics. 
[8] Tuarob, S., Tucker, C. 	S., Salathe, M., and Ram, N., 2013. “Discovering health-related knowledge in social media using ensembles of heterogeneous features”. In Proceedings of the 22Nd ACM International Conference on Conference on Information & Knowledge Manage.ment, CIKM ’13, ACM, pp. 1685–1690. 
[9] Lim, S., Tucker, C. S., and Kumara, S., 2016. “An unsu.pervised machine learning model for discovering latent infectious diseases using social media data”. Journal of Biomedical Informatics. 
[10] Sakaki, T., Okazaki, M., and Matsuo, Y., 2010. 	“Earth.quake shakes twitter users: real-time event detection by social sensors”. In Proceedings of the 19th interna.tional conference on World wide web, WWW ’10, ACM, pp. 851–860. 
[11] Caragea, C., McNeese, N., Jaiswal, A., Traylor, G., Kim, H., Mitra, P., Wu, D., Tapia, A., Giles, L., Jansen, B., et al., 2011. “Classifying text messages for the haiti earthquake”. In Proceedings of the 8th International Con.ference on Information Systems for Crisis Response and Management (ISCRAM2011). 
[12] Bollen, J., Mao, H., and Zeng, X., 2011. 	“Twitter mood predicts the stock market”. Journal of Computational Sci.ence, 2(1), pp. 1–8. 

[13] Zhang, X., Fuehres, H., and Gloor, P., 2012. “Predicting asset value through twitter buzz”. Advances in Collective Intelligence 2011, pp. 23–34. 
[14] Maynard, D., and Greenwood, M. A., 2014. “Who cares about sarcastic tweets? investigating the impact of sar.casm on sentiment analysis”. In Proceedings of LREC. 
[15] Dey, L., and Haque, S., 2009. 	“Studying the effects of noisy text on text mining applications”. In Proceedings of The Third Workshop on Analytics for Noisy Unstruc.tured Text Data, ACM, pp. 107–114. 
[16] Tsur, O., Davidov, D., and Rappoport, A., 2010. “Icwsm.a great catchy name: Semi-supervised recognition of sar.castic sentences in online product reviews.”. In ICWSM. 
[17] Davidov, D., Tsur, O., and Rappoport, A., 2010. 	“Semi-supervised recognition of sarcastic sentences in twitter and amazon”. In Proceedings of the Fourteenth Confer.ence on Computational Natural Language Learning, As.sociation for Computational Linguistics, pp. 107–116. 
[18] Navigli, R., and Velardi, P., 2005. 	“Structural semantic interconnections: a knowledge-based approach to word sense disambiguation”. IEEE transactions on pattern analysis and machine intelligence, 27(7), pp. 1075–1086. 
[19] Muecke, D. C., 1982. Irony and the Ironic. Methuen. 
[20] Gibbs, R. W., 1986. 	“On the psycholinguistics of sar.casm.”. Journal of Experimental Psychology: General, 115(1), p. 3. 
[21] Gibbs, R. W., and Colston, H. L., 2007. 	Irony in lan.guage and thought: A cognitive science reader. Psychol.ogy Press. 
[22] Archak, N., Ghose, A., and Ipeirotis, P. G., 2011. “Deriv.ing the pricing power of product features by mining con.sumer reviews”. Management science, 57(8), pp. 1485– 1509. 
[23] Asur, 	S., and Huberman, B. A., 2010. “Predict.ing the future with social media”. In Web Intelli.gence and Intelligent Agent Technology (WI-IAT), 2010 IEEE/WIC/ACM International Conference on, Vol. 1, IEEE, pp. 492–499. 
[24] Stone, T., and Choi, S.-K., 2014. 	“Visualization tool for interpreting user needs from user-generated content via text mining and classi.cation”. In ASME 2014 In.ternational Design Engineering Technical Conferences and Computers and Information in Engineering Con.ference, American Society of Mechanical Engineers, pp. V02AT03A009–V02AT03A009. 
[25] Zhao, W. X., Jiang, J., Weng, J., He, J., Lim, E.-P., Yan, H., and Li, X., 2011. “Comparing twitter and traditional media using topic models”. In Advances in Information Retrieval. Springer, pp. 338–349. 
[26] YaJuan, D., WEIF uRu, C. Z., Heung, Z. M., and SHUM, Y., 2012. “Twitter topic summarization by ranking tweets using social in.uence and content quality”. In Proceed.ings of the 24th International Conference on Computa.tional Linguistics, pp. 763–780. 
[27] Wang, Y., Wu, H., and Fang, H., 2014. 	“An exploration of tie-breaking for microblog retrieval”. In Advances in 
Information Retrieval. Springer, pp. 713–719. 
[28] Tuarob, S., Tucker, C. S., Salathe, M., and Ram, N., 2015. “Modeling individual-level infection dynamics using so.cial network information”. In Proceedings of the 24th ACM International on Conference on Information and Knowledge Management, ACM, pp. 1501–1510. 
[29] Tuarob, S., and Mitrpanont, J. 	L., 2017. “Automatic discovery of abusive thai language usages in social net.works”. In International Conference on Asian Digital Li.braries, Springer, pp. 267–278. 
[30] Thelwall, 	M., Buckley, K., and Paltoglou, G., 2011. “Sentiment in twitter events”. J. Am. Soc. Inf. Sci. Tech.nol., pp. 406–418. 
[31] Kucuktunc, O., Cambazoglu, B. B., Weber, I., and Fer.hatosmanoglu, H., 2012. “A large-scale sentiment analy.sis for yahoo! answers”. In Proceedings of the .fth ACM international conference on Web search and data mining, WSDM ’12, ACM, pp. 633–642. 
[32] Weber, I., Ukkonen, A., and Gionis, A., 2012. “Answers, not links: extracting tips from yahoo! answers to address how-to web queries”. In Proceedings of the .fth ACM international conference on Web search and data mining, WSDM ’12, ACM, pp. 613–622. 
[33] Blei, D. M., Ng, A. Y., and Jordan, M. I., 2003. 	“La.tent dirichlet allocation”. J. Mach. Learn. Res., 3, Mar., pp. 993–1022. 
[34] Paul, M. J., and Dredze, M., 2011. 	A model for mining public health topics from twitter. Tech. rep. 
[35] Paul, M. J., and Dredze, M., 2011. 	“You are what you tweet: Analyzing twitter for public health.”. In ICWSM, pp. 265–272. 
[36] Ramage, 	D., Dumais, S. T., and Liebling, D. J., 2010. “Characterizing microblogs with topic models.”. ICWSM, 10, pp. 1–1. 
[37] Prier, K. W., Smith, M. S., Giraud-Carrier, C., and Han.son, C. L., 2011. “Identifying health-related topics on twitter”. In Social computing, behavioral-cultural mod.eling and prediction. Springer, pp. 18–25. 
[38] Jin, 	O., Liu, N. N., Zhao, K., Yu, Y., and Yang, Q., 2011. “Transferring topical knowledge from auxiliary long texts for short text clustering”. In Proceedings of the 20th ACM international conference on Information and knowledge management, ACM, pp. 775–784. 
[39] Tuarob, S., and Tucker, C. S., 2016. 	“Automated dis.covery of product preferences in ubiquitous social media data: A case study of automobile market”. In Computer Science and Engineering Conference (ICSEC), 2016 In.ternational, IEEE, pp. 1–6. 
[40] Gonz.alez-Ib.a.nez, R., Muresan, S., and Wacholder, N., 2011. “Identifying sarcasm in twitter: a closer look”. In Proceedings of the 49th Annual Meeting of the Associ.ation for Computational Linguistics: Human Language Technologies: short papers-Volume 2, Association for Computational Linguistics, pp. 581–586. 
[41] Reyes, A., Rosso, P., and Veale, T., 2013. “A multidimen.sional approach for detecting irony in twitter”. Language 
Resources and Evaluation, 47(1), pp. 239–268. 

[42] Ahlqvist, T., 2008. 	Social media roadmaps: exploring the futures triggered by social media. VTT. 
[43] Thelwall, M., Buckley, K., Paltoglou, G., Cai, D., and Kappas, A., 2010. “Sentiment in short strength detec.tion informal text”. J. Am. Soc. Inf. Sci. Technol., 61(12), Dec., pp. 2544–2558. 
[44] Guo, W., Li, H., Ji, H., and Diab, M. T., 2013. “Linking tweets to news: A framework to enrich short text data in social media.”. In ACL (1), Citeseer, pp. 239–249. 
[45] Ramaswamy, S. 	“Comparing the ef.ciency of two clus.tering techniques”. 
[46] Fox, E., 2008. 	Emotion science: cognitive and neuro.scienti.c approaches to understanding human emotions. Palgrave Macmillan. 
[47] Cutting, D., Kupiec, J., Pedersen, J., and Sibun, P., 1992. “A practical part-of-speech tagger”. In Proceedings of the Third Conference on Applied Natural Language Process.ing, ANLC ’92, Association for Computational Linguis.tics, pp. 133–140. 
. 

[48] 	Ozg.ur, A., Cetin, B., and Bingol, H., 2008. “Co-occurrence network of reuters news”. International Jour.nal of Modern Physics C, 19(05), pp. 689–702. 
[49] Jia, S., Yang, C., Liu, J., and Zhang, Z., 2012. 	“An improved information .ltering technology”. In Future Computing, Communication, Control and Management. Springer, pp. 507–512. 
[50] Tuarob, 	S., Mitra, P., and Giles, C. L., 2012. “Im.proving algorithm search using the algorithm co-citation network”. In Proceedings of the 12th ACM/IEEE-CS Joint Conference on Digital Libraries, JCDL ’12, ACM, pp. 277–280. 
[51] Tuarob, S., Bhatia, S., Mitra, P., and Giles, C., 2013. “Automatic detection of pseudocodes in scholarly doc.uments using machine learning”. In Document Analysis and Recognition (ICDAR), 2013 12th International Con.ference on, pp. 738–742. 
[52] Evans, D. A., Handerson, S. K., Monarch, I. A., Pereiro, J., Delon, L., and Hersh, W. R., 1998. Mapping vocabu.laries using latent semantics. Springer. 
[53] Tuarob, S., 	Pouchard, L. C., and Giles, C. L., 2013. “Automatic tag recommendation for metadata annotation using probabilistic topic modeling”. In Proceedings of the 13th ACM/IEEE-CS Joint Conference on Digital Li.braries, JCDL ’13, ACM, pp. 239–248. 
[54] Tuarob, S., Pouchard, L., Mitra, P., and Giles, C., 2015. “A generalized topic modeling approach for automatic document annotation”. International Journal on Digital Libraries, pp. 1–18. 
[55] Cliche, M., 2014 (accessed February 19, 2017). The sar.casm detector: Learning sarcasm from tweets! 
[56] Liu, F., 	Liu, F., and Liu, Y., 2008. “Automatic key.word extraction for the meeting corpus using supervised approach and bigram expansion”. In Spoken Language Technology Workshop, 2008. SLT 2008. IEEE, IEEE, pp. 181–184. 
[57] Martin, 	S., Brown, W. M., Klavans, R., and Boy.ack, K. W., 2011. “Openord: An open-source tool.box for large graph layout”. In IS&T/SPIE Electronic Imaging, International Society for Optics and Photonics, pp. 786806–786806. 
[58] Manning, C. D., Raghavan, P., and Sch.utze, H., 2008. Introduction to Information Retrieval. Cambridge Uni.versity Press, New York, NY, USA. 
[59] Thelwall, M., 2013. “Heart and soul: Sentiment strength detection in the social web with sentistrength”. Cybere.motions, pp. 1–14. 
[60] Tuarob, S., Tucker, C. S., Kumara, S., Giles, C. L., Pin.cus, A. L., Conroy, D. E., and Ram, N., 2017. “How are you feeling?: A personalized methodology for pre.dicting mental states from temporally observable physi.cal and behavioral information”. Journal of Biomedical Informatics, 68, pp. 1 – 19. 
[61] Tuarob, S., Pouchard, L. C., Noy, N., Horsburgh, J. S., and Palanisamy, G. “Onemercury: Towards automatic annotation of environmental science metadata”. In Pro.ceedings of the 2nd International Workshop on Linked Science 2012. 


A Statistics for Feature Characteristics 
The statistics used to describe the characteristics of the product features extracted from the social media data are de.scribed in this section. Given a product s . S, social media message corpus Ms, and the set of extracted features F(Ms), Feature Utilization, Feature Intensity, and Feature Diversity are de.ned below: 
A.1 Feature Utilization 
For a given product s . S, the feature utilization is de.ned as: 
.f .F(Ms) |{m . Ms : f . m}| F . Utilization(s)= (9) 
|F(Ms)| 

The feature utilization quanti.es how frequently on average a product feature is mentioned. The notion was .rst used in [53, 61] as the Tag Utilization metric, and was used to mea.sure how solid and standardized a tag collection is. Similarly, the Feature Utilization measures, overall, how standardized the features of a speci.c product are. 
From Table 3, the products with highest feature utiliza.tion are iPhone 5, iPhone 4S, iPhone 5S, iPhone 4, iPhone 5C, Motorola Droid RAZR, and Samsung Galaxy Nexus re.spectively. It does not come to a surprise to see the iPhone product line having high feature utilization since the product line has been in the market space for a long time and most features are inherited from the very .rst generation (such as tough screen, home button, color (black/white), etc.). After generations, these features may have become standardized as opposed to products with newly emerging features such as Ky.ocera Echo (F-Utilization = 1.36) which distinctly offers two screens and the ability to use two applications at once. 

A.2 Feature Intensity 
Given a product s, the feature intensity is de.ned as: 

| f .F(Ms) {m . Ms : f . m}| F . Intensity(s)= (10) 
|Ms| 

While feature utilization quanti.es the overall quality of the features of a product, the feature intensity quanti.es the volume of discussion in social media about the product fea.tures. It is measured by the proportion of messages related to the features of the product s over all the messages related to 
s. The feature intensity can infer how many of the consumers care to discuss about the product that they are using. 
Interestingly, most of the iPhone products (except newly launched iPhone 5S and iPhone 5C) are among the smartphone products with lowest feature intensity scores. This might be be.cause such products may ave been perceived by the consumers as generally good by word of mouth, which induce other con.sumers to purchase such products without much consideration about the features before making the purchasing decisions. 

A.3 Feature Diversity 
The feature diversity tells how diverse the consumers’ opinions are towards a particular feature. For a feature f of product s . S: 
|Opinion( f , s)| 
. (11) 
F . Diversity( f , s)= . 
.. 
. 
.s ..S, f ..F(Ms) Opinion( f , s . ). 
.f .F(Ms) F . Diversity( f , s)
Avg . F . Diversity(s)= (12) 
|F(Ms)| 
Where Opinion( f , s) is the set of distinct opinions towards the feature f . Recall that the feature extraction algorithm (Al.gorithm 1) also extracts opinions for each extracted feature. The average feature diversity then quanti.es the opinion di.versity in features of a particular product. The products with highest diversity include LG Enlighten, Samsung Exhibit 4G, LG Cosmos Touch, Samsung Dart, Kyocera Echo and iPhone 5C. Note that one could observe that these products are either having highly controversial features (i.e. Kyocera Echo which offers dual screens with predictive text input and Samsung Ex.hibit 4G which offers dual cameras with surprisingly cheap prices.) or newly launched (i.e. iPhone 5C), all of which could incite diverse opinion-related discussion about the product fea.tures. 



